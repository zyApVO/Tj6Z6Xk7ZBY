{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjIfsJH0c5sPL57oh73fGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajwalBirwadkar/GAN-Experiential-Learning/blob/main/GAN_Experiential_Learning_Tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name : Prajwal Birwadkar**\n",
        "\n",
        "**PRN: 24070149003**"
      ],
      "metadata": {
        "id": "NePsYEIoTEs1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNNjaMwhBGjH",
        "outputId": "ec2dcd48-b630-40f6-8c07-f1e14160f7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.13.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.2-py3-none-any.whl (931 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.13.1-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.13.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.6.2\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "img_size = 32\n",
        "channels = 3\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "sample_interval = 10  # Save generated images every 10 epochs\n",
        "\n",
        "# Data loading and preprocessing for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator (shared across all GAN variants)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 8 * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 8, 8)),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, channels, 3, padding=1),\n",
        "            nn.Tanh()  # Output range: [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "# Discriminator for BCE GAN\n",
        "class DiscriminatorBCE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorBCE, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 1),\n",
        "            nn.Sigmoid()  # Output probability\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "# Discriminator for LS-GAN (no sigmoid)\n",
        "class DiscriminatorLS(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorLS, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 1)  # Real-valued output\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n"
      ],
      "metadata": {
        "id": "9tpXGm7bCh4Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Critic for WGAN (no batch norm, no sigmoid)\n",
        "class CriticWGAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CriticWGAN, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 1)  # Real-valued output\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "# Function to save generated images\n",
        "def save_generated_images(generator, epoch, latent_dim, num_images=64, filename='generated_images'):\n",
        "    z = torch.randn(num_images, latent_dim).to(device)\n",
        "    gen_imgs = generator(z)\n",
        "    save_image(gen_imgs, f\"{filename}_epoch_{epoch}.png\", normalize=True)\n",
        "\n",
        "# Training function for BCE GAN\n",
        "def train_bce_gan(generator, discriminator, dataloader, epochs):\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (imgs, _) in enumerate(dataloader):\n",
        "            real = torch.ones(imgs.size(0), 1).to(device)\n",
        "            fake = torch.zeros(imgs.size(0), 1).to(device)\n",
        "            real_imgs = imgs.to(device)\n",
        "            z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
        "            gen_imgs = generator(z)\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            real_loss = criterion(discriminator(real_imgs), real)\n",
        "            fake_loss = criterion(discriminator(gen_imgs.detach()), fake)\n",
        "            d_loss = real_loss + fake_loss\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            g_loss = criterion(discriminator(gen_imgs), real)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        print(f\"[BCE GAN] Epoch {epoch}/{epochs}, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "        if epoch % sample_interval == 0:\n",
        "            save_generated_images(generator, epoch, latent_dim, filename='bce_gan_images')\n",
        "\n"
      ],
      "metadata": {
        "id": "ju3uzL3fDiTp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function for LS-GAN\n",
        "def train_ls_gan(generator, discriminator, dataloader, epochs):\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (imgs, _) in enumerate(dataloader):\n",
        "            real = torch.ones(imgs.size(0), 1).to(device)\n",
        "            fake = torch.zeros(imgs.size(0), 1).to(device)\n",
        "            real_imgs = imgs.to(device)\n",
        "            z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
        "            gen_imgs = generator(z)\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            real_loss = criterion(discriminator(real_imgs), real)\n",
        "            fake_loss = criterion(discriminator(gen_imgs.detach()), fake)\n",
        "            d_loss = real_loss + fake_loss\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            g_loss = criterion(discriminator(gen_imgs), real)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        print(f\"[LS-GAN] Epoch {epoch}/{epochs}, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "        if epoch % sample_interval == 0:\n",
        "            save_generated_images(generator, epoch, latent_dim, filename='ls_gan_images')\n",
        "\n"
      ],
      "metadata": {
        "id": "RTcdgURPDnrw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function for WGAN\n",
        "def train_wgan(generator, critic, dataloader, epochs, n_critic=5, clip_value=0.01):\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    optimizer_C = optim.Adam(critic.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (imgs, _) in enumerate(dataloader):\n",
        "            real_imgs = imgs.to(device)\n",
        "            z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
        "            gen_imgs = generator(z)\n",
        "\n",
        "            # Train Critic\n",
        "            for _ in range(n_critic):\n",
        "                optimizer_C.zero_grad()\n",
        "                real_loss = critic(real_imgs).mean()\n",
        "                fake_loss = critic(gen_imgs.detach()).mean()\n",
        "                c_loss = fake_loss - real_loss\n",
        "                c_loss.backward()\n",
        "                optimizer_C.step()\n",
        "                # Weight clipping for Lipschitz constraint\n",
        "                for p in critic.parameters():\n",
        "                    p.data.clamp_(-clip_value, clip_value)\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            g_loss = -critic(gen_imgs).mean()\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        print(f\"[WGAN] Epoch {epoch}/{epochs}, C Loss: {c_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "        if epoch % sample_interval == 0:\n",
        "            save_generated_images(generator, epoch, latent_dim, filename='wgan_images')\n",
        "\n"
      ],
      "metadata": {
        "id": "19gd_ccaDwYh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize models\n",
        "    generator_bce = Generator().to(device)\n",
        "    discriminator_bce = DiscriminatorBCE().to(device)\n",
        "    generator_ls = Generator().to(device)\n",
        "    discriminator_ls = DiscriminatorLS().to(device)\n",
        "    generator_wgan = Generator().to(device)\n",
        "    critic_wgan = CriticWGAN().to(device)\n",
        "\n",
        "    # Train BCE GAN\n",
        "    print(\"Training BCE GAN...\")\n",
        "    train_bce_gan(generator_bce, discriminator_bce, dataloader, epochs)\n",
        "    torch.save(generator_bce.state_dict(), 'generator_bce.pth')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZs5C0d1D1gY",
        "outputId": "73715dde-2259-4f1f-9b38-5677cc24851c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BCE GAN...\n",
            "[BCE GAN] Epoch 0/50, D Loss: 1.7901, G Loss: 0.3826\n",
            "[BCE GAN] Epoch 1/50, D Loss: 0.9169, G Loss: 1.5627\n",
            "[BCE GAN] Epoch 2/50, D Loss: 0.9553, G Loss: 1.5259\n",
            "[BCE GAN] Epoch 3/50, D Loss: 0.9091, G Loss: 1.7885\n",
            "[BCE GAN] Epoch 4/50, D Loss: 0.8159, G Loss: 1.7274\n",
            "[BCE GAN] Epoch 5/50, D Loss: 0.9142, G Loss: 2.3132\n",
            "[BCE GAN] Epoch 6/50, D Loss: 0.8072, G Loss: 1.3929\n",
            "[BCE GAN] Epoch 7/50, D Loss: 0.6925, G Loss: 1.7980\n",
            "[BCE GAN] Epoch 8/50, D Loss: 0.8700, G Loss: 2.8023\n",
            "[BCE GAN] Epoch 9/50, D Loss: 0.6832, G Loss: 1.8592\n",
            "[BCE GAN] Epoch 10/50, D Loss: 0.8071, G Loss: 3.9306\n",
            "[BCE GAN] Epoch 11/50, D Loss: 1.1767, G Loss: 1.0529\n",
            "[BCE GAN] Epoch 12/50, D Loss: 1.0056, G Loss: 3.6858\n",
            "[BCE GAN] Epoch 13/50, D Loss: 1.2526, G Loss: 1.2303\n",
            "[BCE GAN] Epoch 14/50, D Loss: 0.6966, G Loss: 3.3356\n",
            "[BCE GAN] Epoch 15/50, D Loss: 0.7845, G Loss: 2.3956\n",
            "[BCE GAN] Epoch 16/50, D Loss: 0.4945, G Loss: 2.7821\n",
            "[BCE GAN] Epoch 17/50, D Loss: 0.5503, G Loss: 2.7422\n",
            "[BCE GAN] Epoch 18/50, D Loss: 0.9683, G Loss: 0.8613\n",
            "[BCE GAN] Epoch 19/50, D Loss: 0.4331, G Loss: 2.5044\n",
            "[BCE GAN] Epoch 20/50, D Loss: 0.5890, G Loss: 3.1431\n",
            "[BCE GAN] Epoch 21/50, D Loss: 0.4462, G Loss: 4.0384\n",
            "[BCE GAN] Epoch 22/50, D Loss: 0.7915, G Loss: 1.5058\n",
            "[BCE GAN] Epoch 23/50, D Loss: 0.2822, G Loss: 3.2896\n",
            "[BCE GAN] Epoch 24/50, D Loss: 0.6858, G Loss: 2.8789\n",
            "[BCE GAN] Epoch 25/50, D Loss: 0.6463, G Loss: 2.3423\n",
            "[BCE GAN] Epoch 26/50, D Loss: 0.3878, G Loss: 3.2840\n",
            "[BCE GAN] Epoch 27/50, D Loss: 0.5198, G Loss: 1.5868\n",
            "[BCE GAN] Epoch 28/50, D Loss: 0.3875, G Loss: 3.1217\n",
            "[BCE GAN] Epoch 29/50, D Loss: 0.9009, G Loss: 4.8560\n",
            "[BCE GAN] Epoch 30/50, D Loss: 0.2097, G Loss: 3.1384\n",
            "[BCE GAN] Epoch 31/50, D Loss: 0.7350, G Loss: 1.4942\n",
            "[BCE GAN] Epoch 32/50, D Loss: 0.8431, G Loss: 2.7495\n",
            "[BCE GAN] Epoch 33/50, D Loss: 0.6149, G Loss: 4.2888\n",
            "[BCE GAN] Epoch 34/50, D Loss: 0.8521, G Loss: 7.4877\n",
            "[BCE GAN] Epoch 35/50, D Loss: 0.5545, G Loss: 6.0760\n",
            "[BCE GAN] Epoch 36/50, D Loss: 0.5178, G Loss: 2.8360\n",
            "[BCE GAN] Epoch 37/50, D Loss: 0.7645, G Loss: 2.6866\n",
            "[BCE GAN] Epoch 38/50, D Loss: 0.4961, G Loss: 2.7518\n",
            "[BCE GAN] Epoch 39/50, D Loss: 0.5744, G Loss: 1.8524\n",
            "[BCE GAN] Epoch 40/50, D Loss: 0.5047, G Loss: 3.2642\n",
            "[BCE GAN] Epoch 41/50, D Loss: 0.8614, G Loss: 2.3368\n",
            "[BCE GAN] Epoch 42/50, D Loss: 0.0888, G Loss: 4.3843\n",
            "[BCE GAN] Epoch 43/50, D Loss: 0.0965, G Loss: 4.3187\n",
            "[BCE GAN] Epoch 44/50, D Loss: 0.2327, G Loss: 3.3639\n",
            "[BCE GAN] Epoch 45/50, D Loss: 0.1425, G Loss: 4.3868\n",
            "[BCE GAN] Epoch 46/50, D Loss: 2.2066, G Loss: 4.2469\n",
            "[BCE GAN] Epoch 47/50, D Loss: 0.3711, G Loss: 5.5055\n",
            "[BCE GAN] Epoch 48/50, D Loss: 0.7125, G Loss: 2.2708\n",
            "[BCE GAN] Epoch 49/50, D Loss: 1.1439, G Loss: 1.4281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Train LS-GAN\n",
        "    print(\"Training LS-GAN...\")\n",
        "    train_ls_gan(generator_ls, discriminator_ls, dataloader, epochs)\n",
        "    torch.save(generator_ls.state_dict(), 'generator_ls.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "vbGf2SHlD17y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17dbed89-eee6-47e6-f61a-d3db99c1e462"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LS-GAN...\n",
            "[LS-GAN] Epoch 0/50, D Loss: 0.3399, G Loss: 0.5519\n",
            "[LS-GAN] Epoch 1/50, D Loss: 0.4847, G Loss: 0.3407\n",
            "[LS-GAN] Epoch 2/50, D Loss: 0.1509, G Loss: 1.3398\n",
            "[LS-GAN] Epoch 3/50, D Loss: 0.3124, G Loss: 1.1296\n",
            "[LS-GAN] Epoch 4/50, D Loss: 0.1637, G Loss: 0.9235\n",
            "[LS-GAN] Epoch 5/50, D Loss: 0.1698, G Loss: 0.5785\n",
            "[LS-GAN] Epoch 6/50, D Loss: 0.2135, G Loss: 1.5788\n",
            "[LS-GAN] Epoch 7/50, D Loss: 0.4181, G Loss: 0.8506\n",
            "[LS-GAN] Epoch 8/50, D Loss: 0.2281, G Loss: 0.5354\n",
            "[LS-GAN] Epoch 9/50, D Loss: 0.1636, G Loss: 0.7851\n",
            "[LS-GAN] Epoch 10/50, D Loss: 0.3046, G Loss: 0.8330\n",
            "[LS-GAN] Epoch 11/50, D Loss: 0.1447, G Loss: 1.2773\n",
            "[LS-GAN] Epoch 12/50, D Loss: 0.7511, G Loss: 0.0486\n",
            "[LS-GAN] Epoch 13/50, D Loss: 0.2096, G Loss: 1.4310\n",
            "[LS-GAN] Epoch 14/50, D Loss: 0.3126, G Loss: 0.9385\n",
            "[LS-GAN] Epoch 15/50, D Loss: 0.3721, G Loss: 1.6163\n",
            "[LS-GAN] Epoch 16/50, D Loss: 0.1552, G Loss: 0.8956\n",
            "[LS-GAN] Epoch 17/50, D Loss: 0.2662, G Loss: 1.6505\n",
            "[LS-GAN] Epoch 18/50, D Loss: 0.3481, G Loss: 0.5720\n",
            "[LS-GAN] Epoch 19/50, D Loss: 0.5237, G Loss: 0.1933\n",
            "[LS-GAN] Epoch 20/50, D Loss: 0.5187, G Loss: 2.7415\n",
            "[LS-GAN] Epoch 21/50, D Loss: 0.2365, G Loss: 1.5737\n",
            "[LS-GAN] Epoch 22/50, D Loss: 0.3932, G Loss: 1.4024\n",
            "[LS-GAN] Epoch 23/50, D Loss: 0.3335, G Loss: 1.5833\n",
            "[LS-GAN] Epoch 24/50, D Loss: 0.3599, G Loss: 0.3575\n",
            "[LS-GAN] Epoch 25/50, D Loss: 0.2668, G Loss: 1.7158\n",
            "[LS-GAN] Epoch 26/50, D Loss: 0.5731, G Loss: 1.8110\n",
            "[LS-GAN] Epoch 27/50, D Loss: 0.1742, G Loss: 0.8360\n",
            "[LS-GAN] Epoch 28/50, D Loss: 0.1694, G Loss: 0.8535\n",
            "[LS-GAN] Epoch 29/50, D Loss: 0.2283, G Loss: 1.9327\n",
            "[LS-GAN] Epoch 30/50, D Loss: 0.2474, G Loss: 0.3937\n",
            "[LS-GAN] Epoch 31/50, D Loss: 0.1398, G Loss: 0.6579\n",
            "[LS-GAN] Epoch 32/50, D Loss: 0.2460, G Loss: 0.2960\n",
            "[LS-GAN] Epoch 33/50, D Loss: 0.2732, G Loss: 0.5223\n",
            "[LS-GAN] Epoch 34/50, D Loss: 0.2262, G Loss: 0.2257\n",
            "[LS-GAN] Epoch 35/50, D Loss: 0.4136, G Loss: 0.2813\n",
            "[LS-GAN] Epoch 36/50, D Loss: 0.2759, G Loss: 1.2833\n",
            "[LS-GAN] Epoch 37/50, D Loss: 0.1162, G Loss: 0.6685\n",
            "[LS-GAN] Epoch 38/50, D Loss: 0.2449, G Loss: 1.2199\n",
            "[LS-GAN] Epoch 39/50, D Loss: 0.1108, G Loss: 1.0388\n",
            "[LS-GAN] Epoch 40/50, D Loss: 0.1556, G Loss: 0.3657\n",
            "[LS-GAN] Epoch 41/50, D Loss: 0.2514, G Loss: 0.6546\n",
            "[LS-GAN] Epoch 42/50, D Loss: 0.0877, G Loss: 0.7876\n",
            "[LS-GAN] Epoch 43/50, D Loss: 0.1680, G Loss: 0.8695\n",
            "[LS-GAN] Epoch 44/50, D Loss: 0.1454, G Loss: 1.4277\n",
            "[LS-GAN] Epoch 45/50, D Loss: 0.4324, G Loss: 0.0382\n",
            "[LS-GAN] Epoch 46/50, D Loss: 0.1609, G Loss: 0.3934\n",
            "[LS-GAN] Epoch 47/50, D Loss: 0.1435, G Loss: 1.6470\n",
            "[LS-GAN] Epoch 48/50, D Loss: 0.1511, G Loss: 0.4520\n",
            "[LS-GAN] Epoch 49/50, D Loss: 0.2368, G Loss: 1.2627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Train WGAN\n",
        "    print(\"Training WGAN...\")\n",
        "    train_wgan(generator_wgan, critic_wgan, dataloader, epochs)\n",
        "    torch.save(generator_wgan.state_dict(), 'generator_wgan.pth')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b-8oDLZ4Zo7",
        "outputId": "4d8859a3-3978-4b3f-ea86-b40b772a9942"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training WGAN...\n",
            "[WGAN] Epoch 0/50, C Loss: 0.5528, G Loss: 1.4260\n",
            "[WGAN] Epoch 1/50, C Loss: 0.3721, G Loss: -2.8018\n",
            "[WGAN] Epoch 2/50, C Loss: -0.0122, G Loss: -0.0229\n",
            "[WGAN] Epoch 3/50, C Loss: 0.1817, G Loss: 2.2143\n",
            "[WGAN] Epoch 4/50, C Loss: -0.0383, G Loss: 0.0366\n",
            "[WGAN] Epoch 5/50, C Loss: -1.5126, G Loss: -10.6114\n",
            "[WGAN] Epoch 6/50, C Loss: 0.3141, G Loss: 0.4430\n",
            "[WGAN] Epoch 7/50, C Loss: -2.0881, G Loss: 8.1316\n",
            "[WGAN] Epoch 8/50, C Loss: -3.3487, G Loss: 8.2016\n",
            "[WGAN] Epoch 9/50, C Loss: -1.2108, G Loss: 8.5983\n",
            "[WGAN] Epoch 10/50, C Loss: -0.9548, G Loss: 8.6378\n",
            "[WGAN] Epoch 11/50, C Loss: -2.0376, G Loss: 9.6060\n",
            "[WGAN] Epoch 12/50, C Loss: -1.1277, G Loss: 9.4575\n",
            "[WGAN] Epoch 13/50, C Loss: -1.2971, G Loss: 11.1078\n",
            "[WGAN] Epoch 14/50, C Loss: -0.2178, G Loss: 9.9282\n",
            "[WGAN] Epoch 15/50, C Loss: -0.8622, G Loss: 13.7578\n",
            "[WGAN] Epoch 16/50, C Loss: -3.0287, G Loss: -3.2560\n",
            "[WGAN] Epoch 17/50, C Loss: -1.2163, G Loss: -11.4953\n",
            "[WGAN] Epoch 18/50, C Loss: -0.0069, G Loss: 0.1502\n",
            "[WGAN] Epoch 19/50, C Loss: -0.0045, G Loss: 0.2248\n",
            "[WGAN] Epoch 20/50, C Loss: -1.6129, G Loss: -13.6137\n",
            "[WGAN] Epoch 21/50, C Loss: -1.4970, G Loss: -9.7430\n",
            "[WGAN] Epoch 22/50, C Loss: 0.8521, G Loss: -3.2957\n",
            "[WGAN] Epoch 23/50, C Loss: -0.1195, G Loss: 0.1853\n",
            "[WGAN] Epoch 24/50, C Loss: -0.7605, G Loss: 2.9455\n",
            "[WGAN] Epoch 25/50, C Loss: -0.6266, G Loss: 0.5007\n",
            "[WGAN] Epoch 26/50, C Loss: 0.0980, G Loss: 1.7189\n",
            "[WGAN] Epoch 27/50, C Loss: -2.6091, G Loss: -8.4257\n",
            "[WGAN] Epoch 28/50, C Loss: 0.9066, G Loss: -3.2134\n",
            "[WGAN] Epoch 29/50, C Loss: -0.1512, G Loss: -2.5780\n",
            "[WGAN] Epoch 30/50, C Loss: 0.0059, G Loss: 0.0485\n",
            "[WGAN] Epoch 31/50, C Loss: -0.4754, G Loss: -4.7914\n",
            "[WGAN] Epoch 32/50, C Loss: 0.8978, G Loss: 16.9145\n",
            "[WGAN] Epoch 33/50, C Loss: 0.3266, G Loss: 3.9198\n",
            "[WGAN] Epoch 34/50, C Loss: -0.1216, G Loss: -0.1378\n",
            "[WGAN] Epoch 35/50, C Loss: -0.0327, G Loss: 0.2155\n",
            "[WGAN] Epoch 36/50, C Loss: -0.0398, G Loss: 0.0386\n",
            "[WGAN] Epoch 37/50, C Loss: 0.0005, G Loss: -0.0092\n",
            "[WGAN] Epoch 38/50, C Loss: -0.0826, G Loss: 0.7479\n",
            "[WGAN] Epoch 39/50, C Loss: -2.4465, G Loss: 10.7822\n",
            "[WGAN] Epoch 40/50, C Loss: -0.0190, G Loss: 7.7189\n",
            "[WGAN] Epoch 41/50, C Loss: -0.1774, G Loss: 7.0571\n",
            "[WGAN] Epoch 42/50, C Loss: 0.0962, G Loss: 9.2047\n",
            "[WGAN] Epoch 43/50, C Loss: -0.0244, G Loss: 1.5634\n",
            "[WGAN] Epoch 44/50, C Loss: -0.2948, G Loss: 1.1194\n",
            "[WGAN] Epoch 45/50, C Loss: 0.4701, G Loss: -3.8492\n",
            "[WGAN] Epoch 46/50, C Loss: 2.4907, G Loss: -14.5146\n",
            "[WGAN] Epoch 47/50, C Loss: 0.2334, G Loss: -1.3548\n",
            "[WGAN] Epoch 48/50, C Loss: -0.0020, G Loss: -0.0270\n",
            "[WGAN] Epoch 49/50, C Loss: 0.0207, G Loss: -0.4041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import inception_v3\n",
        "import numpy as np\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pretrained Inception V3\n",
        "inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
        "inception_model.eval()\n",
        "\n",
        "# Function to preprocess images for Inception V3\n",
        "def preprocess_images(images):\n",
        "    # Assuming images are in [-1, 1], convert to [0, 1]\n",
        "    images = (images * 0.5 + 0.5).clamp(0, 1)\n",
        "    # Resize to 299x299 as expected by Inception V3\n",
        "    images = F.interpolate(images, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "    # Normalize to match Inception V3 input (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)\n",
        "    images = (images - mean) / std\n",
        "    return images\n",
        "\n",
        "# Compute Inception Score\n",
        "def compute_inception_score_manual(generator, num_samples=1000, batch_size=50):\n",
        "    generator.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_samples // batch_size):\n",
        "            noise = torch.randn(batch_size, 100).to(device)  # Adjust 100 to your latent dim\n",
        "            fake_images = generator(noise)\n",
        "            fake_images = preprocess_images(fake_images)\n",
        "            pred = inception_model(fake_images)\n",
        "            preds.append(F.softmax(pred, dim=1).cpu().numpy())\n",
        "    preds = np.concatenate(preds, axis=0)\n",
        "\n",
        "    # Calculate IS\n",
        "    scores = []\n",
        "    for i in range(0, len(preds), batch_size):\n",
        "        p = preds[i:i+batch_size]\n",
        "        kl_div = p * (np.log(p + 1e-16) - np.log(np.mean(p, axis=0, keepdims=True) + 1e-16))\n",
        "        scores.append(np.exp(np.mean(kl_div.sum(axis=1))))\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Compute FID\n",
        "def compute_fid_manual(generator, real_images, num_samples=1000, batch_size=50):\n",
        "    generator.eval()\n",
        "\n",
        "    # Get real image features\n",
        "    with torch.no_grad():\n",
        "        real_images = preprocess_images(real_images)\n",
        "        real_features = inception_model(real_images).cpu().numpy()\n",
        "\n",
        "    # Get fake image features\n",
        "    fake_features = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_samples // batch_size):\n",
        "            noise = torch.randn(batch_size, 100).to(device)  # Adjust 100 to your latent dim\n",
        "            fake_images = generator(noise)\n",
        "            fake_images = preprocess_images(fake_images)\n",
        "            feat = inception_model(fake_images).cpu().numpy()\n",
        "            fake_features.append(feat)\n",
        "    fake_features = np.concatenate(fake_features, axis=0)\n",
        "\n",
        "    # Calculate mean and covariance\n",
        "    mu_real, sigma_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
        "    mu_fake, sigma_fake = np.mean(fake_features, axis=0), np.cov(fake_features, rowvar=False)\n",
        "\n",
        "    # FID calculation\n",
        "    diff = mu_real - mu_fake\n",
        "    covmean = sqrtm(sigma_real.dot(sigma_fake))\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    fid = diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2 * covmean)\n",
        "    return fid\n",
        "\n",
        "# Example usage\n",
        "real_images = next(iter(dataloader))[0].to(device)[:1000]  # Adjust size as needed\n",
        "\n",
        "print(\"Evaluating BCE GAN...\")\n",
        "is_score_bce = compute_inception_score_manual(generator_bce)\n",
        "fid_score_bce = compute_fid_manual(generator_bce, real_images)\n",
        "print(f\"BCE GAN - IS: {is_score_bce:.4f}, FID: {fid_score_bce:.4f}\")\n",
        "\n",
        "print(\"Evaluating LS-GAN...\")\n",
        "is_score_ls = compute_inception_score_manual(generator_ls)\n",
        "fid_score_ls = compute_fid_manual(generator_ls, real_images)\n",
        "print(f\"LS-GAN - IS: {is_score_ls:.4f}, FID: {fid_score_ls:.4f}\")\n",
        "\n",
        "print(\"Evaluating WGAN...\")\n",
        "is_score_wgan = compute_inception_score_manual(generator_wgan)\n",
        "fid_score_wgan = compute_fid_manual(generator_wgan, real_images)\n",
        "print(f\"WGAN - IS: {is_score_wgan:.4f}, FID: {fid_score_wgan:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZPvyHxJLYwV",
        "outputId": "874ad3d5-a419-41c8-ccab-6c59890dc080"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating BCE GAN...\n",
            "BCE GAN - IS: 4.7519, FID: 720.1011\n",
            "Evaluating LS-GAN...\n",
            "LS-GAN - IS: 4.4756, FID: 706.1688\n",
            "Evaluating WGAN...\n",
            "WGAN - IS: 2.2496, FID: 1085.4244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis\n",
        "\n",
        "Inception Score (IS):\n",
        "A higher IS generally indicates that the generated images are both diverse and of high quality. Here, the BCE GAN and LS-GAN have significantly higher scores than the WGAN, suggesting they produce more recognizable and varied images.\n",
        "\n",
        "Fréchet Inception Distance (FID):\n",
        "A lower FID implies that the generated images are closer in distribution to the real images. LS-GAN has the lowest FID (706.1688), with BCE GAN following closely, while WGAN's high FID indicates a larger discrepancy from the real image distribution.\n",
        "\n",
        "Conclusion\n",
        "BCE GAN and LS-GAN are performing comparably well in terms of both IS and FID, with LS-GAN slightly better on the FID metric.\n",
        "WGAN appears to be underperforming compared to the other two, as reflected by both its lower IS and higher FID."
      ],
      "metadata": {
        "id": "cSOIKl0OYJ4V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dx6am24IM_yW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}